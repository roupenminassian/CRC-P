{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Global Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from collections import defaultdict\n",
    "\n",
    "# Update with your folder path\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/'\n",
    "\n",
    "# Initialize data structures\n",
    "subject_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Sampling frequency\n",
    "fs = 500\n",
    "\n",
    "# Initialize aggregation variables\n",
    "total_weighted_precision = 0\n",
    "total_weighted_recall = 0\n",
    "total_weighted_f1 = 0\n",
    "total_support = 0\n",
    "total_accuracy = 0\n",
    "total_subjects = 0\n",
    "\n",
    "# Load and organize data by subject and activity\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):\n",
    "        subject, activity = filename.split('_')[0], filename.split('_')[1].split('.')[0]\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "        subject_data[subject][activity] = record\n",
    "\n",
    "# Prepare data for training/testing\n",
    "train_features, test_features = [], []\n",
    "train_labels, test_labels = [], []\n",
    "\n",
    "# Initialize a dictionary to hold models for each subject\n",
    "subject_models = {}\n",
    "\n",
    "# Process data for each subject\n",
    "for subject in subject_data.keys():\n",
    "    train_features, test_features = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "\n",
    "    print(f\"Processing subject: {subject}\")\n",
    "\n",
    "    for activity in subject_data[subject].keys():\n",
    "        record = subject_data[subject][activity]\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Perform 80/20 split\n",
    "        train_size = int(0.8 * len(ecg_signal))\n",
    "        ecg_train, ecg_test = ecg_signal[:train_size], ecg_signal[train_size:]\n",
    "        pleth_2_train, pleth_2_test = pleth_2_signal[:train_size], pleth_2_signal[train_size:]\n",
    "\n",
    "        # Extract global features and prefix the feature names\n",
    "        ecg_train_features_raw = global_features(ecg_train, fs, is_ecg=True)\n",
    "        pleth_2_train_features_raw = global_features(pleth_2_train, fs, is_ecg=False)\n",
    "        ecg_test_features_raw = global_features(ecg_test, fs, is_ecg=True)\n",
    "        pleth_2_test_features_raw = global_features(pleth_2_test, fs, is_ecg=False)\n",
    "\n",
    "        ecg_train_features = {\"ECG_\" + k: v for k, v in ecg_train_features_raw.items()}\n",
    "        pleth_2_train_features = {\"PPG_\" + k: v for k, v in pleth_2_train_features_raw.items()}\n",
    "        ecg_test_features = {\"ECG_\" + k: v for k, v in ecg_test_features_raw.items()}\n",
    "        pleth_2_test_features = {\"PPG_\" + k: v for k, v in pleth_2_test_features_raw.items()}\n",
    "\n",
    "        # Combine features and append to training/testing sets\n",
    "        train_features.append({**ecg_train_features, **pleth_2_train_features})\n",
    "        test_features.append({**ecg_test_features, **pleth_2_test_features})\n",
    "\n",
    "        train_labels.append(activity)\n",
    "        test_labels.append(activity)\n",
    "\n",
    "    # Convert features and labels to NumPy arrays\n",
    "    X_train = np.array([list(f.values()) for f in train_features])\n",
    "    y_train = np.array(train_labels)\n",
    "    X_test = np.array([list(f.values()) for f in test_features])\n",
    "    y_test = np.array(test_labels)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "    clf.fit(X_train_normalized, y_train)\n",
    "\n",
    "    # Store the model for this subject\n",
    "    subject_models[subject] = clf\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = clf.predict(X_test_normalized)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy for {subject}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Aggregate metrics\n",
    "    metrics = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    precision_values, recall_values, f1_values, support_values = metrics\n",
    "\n",
    "    total_support_subject = sum(support_values)\n",
    "    weighted_precision = sum(p * s for p, s in zip(precision_values, support_values)) / total_support_subject\n",
    "    weighted_recall = sum(r * s for r, s in zip(recall_values, support_values)) / total_support_subject\n",
    "    weighted_f1 = sum(f * s for f, s in zip(f1_values, support_values)) / total_support_subject\n",
    "\n",
    "    total_weighted_precision += weighted_precision * total_support_subject\n",
    "    total_weighted_recall += weighted_recall * total_support_subject\n",
    "    total_weighted_f1 += weighted_f1 * total_support_subject\n",
    "    total_support += total_support_subject\n",
    "    total_accuracy += accuracy\n",
    "    total_subjects += 1\n",
    "\n",
    "    # Calculate additional metrics (Recall, F1, Precision)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Visualize Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=['sit', 'walk', 'run'], yticklabels=['sit', 'walk', 'run'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Calculate and plot SHAP values\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "    shap_values = explainer.shap_values(X_test_normalized)\n",
    "\n",
    "    # Get the feature names (assuming all features are keys in one of the feature dictionaries)\n",
    "    feature_names = list(train_features[0].keys())\n",
    "\n",
    "    # Plot SHAP values for each class\n",
    "    for i, label in enumerate(clf.classes_):\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "        # Display SHAP summary plot\n",
    "        shap.summary_plot(shap_values[i], X_test, feature_names=feature_names, show=False)\n",
    "\n",
    "        # Create Explanation object for bar plot\n",
    "        expected_value = explainer.expected_value[i]\n",
    "        explanation = shap.Explanation(values=shap_values[i],\n",
    "                                      base_values=expected_value,\n",
    "                                      data=X_test,\n",
    "                                      feature_names=feature_names)\n",
    "\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "        # Display SHAP bar plot\n",
    "        shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Calculate final aggregated metrics\n",
    "final_precision = total_weighted_precision / total_support\n",
    "final_recall = total_weighted_recall / total_support\n",
    "final_f1 = total_weighted_f1 / total_support\n",
    "final_accuracy = total_accuracy / total_subjects\n",
    "\n",
    "final_metrics = {\n",
    "    \"Precision\": final_precision,\n",
    "    \"Recall\": final_recall,\n",
    "    \"F1-Score\": final_f1,\n",
    "    \"Support\": total_support,\n",
    "    \"Accuracy\": final_accuracy\n",
    "}\n",
    "\n",
    "print(\"Final Aggregated Metrics:\", final_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "from collections import defaultdict\n",
    "\n",
    "# Update with your folder path\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/'\n",
    "\n",
    "# Initialize data structures\n",
    "subject_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Sampling frequency\n",
    "fs = 500\n",
    "\n",
    "# Initialize aggregation variables\n",
    "total_weighted_precision = 0\n",
    "total_weighted_recall = 0\n",
    "total_weighted_f1 = 0\n",
    "total_support = 0\n",
    "total_accuracy = 0\n",
    "total_subjects = 0\n",
    "\n",
    "# Load and organize data by subject and activity\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):\n",
    "        subject, activity = filename.split('_')[0], filename.split('_')[1].split('.')[0]\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "        subject_data[subject][activity] = record\n",
    "\n",
    "# Prepare data for training/testing\n",
    "train_features, test_features = [], []\n",
    "train_labels, test_labels = [], []\n",
    "\n",
    "# Initialize a dictionary to hold models for each subject\n",
    "subject_models = {}\n",
    "\n",
    "# Process data for each subject\n",
    "for subject in subject_data.keys():\n",
    "    train_features, test_features = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "\n",
    "    print(f\"Processing subject: {subject}\")\n",
    "\n",
    "    for activity in subject_data[subject].keys():\n",
    "        record = subject_data[subject][activity]\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Perform 80/20 split\n",
    "        train_size = int(0.8 * len(ecg_signal))\n",
    "        ecg_train, ecg_test = ecg_signal[:train_size], ecg_signal[train_size:]\n",
    "        pleth_2_train, pleth_2_test = pleth_2_signal[:train_size], pleth_2_signal[train_size:]\n",
    "\n",
    "        # Extract global features and prefix the feature names\n",
    "        ecg_train_features_raw = global_features(ecg_train, fs, is_ecg=True)\n",
    "        pleth_2_train_features_raw = global_features(pleth_2_train, fs, is_ecg=False)\n",
    "        ecg_test_features_raw = global_features(ecg_test, fs, is_ecg=True)\n",
    "        pleth_2_test_features_raw = global_features(pleth_2_test, fs, is_ecg=False)\n",
    "\n",
    "        ecg_train_features = {\"ECG_\" + k: v for k, v in ecg_train_features_raw.items()}\n",
    "        pleth_2_train_features = {\"PPG_\" + k: v for k, v in pleth_2_train_features_raw.items()}\n",
    "        ecg_test_features = {\"ECG_\" + k: v for k, v in ecg_test_features_raw.items()}\n",
    "        pleth_2_test_features = {\"PPG_\" + k: v for k, v in pleth_2_test_features_raw.items()}\n",
    "\n",
    "       # Convert 'run' and 'walk' labels to 'movement', 'sit' to 'rest'\n",
    "        converted_activity = activity\n",
    "        if activity in ['run', 'walk']:\n",
    "            converted_activity = 'movement'\n",
    "        elif activity == 'sit':\n",
    "            converted_activity = 'rest'\n",
    "\n",
    "        # Combine features and append to training/testing sets\n",
    "        train_features.append({**ecg_train_features, **pleth_2_train_features})\n",
    "        test_features.append({**ecg_test_features, **pleth_2_test_features})\n",
    "\n",
    "        train_labels.append(converted_activity)\n",
    "        test_labels.append(converted_activity)\n",
    "\n",
    "    # Convert features and labels to NumPy arrays\n",
    "    X_train = np.array([list(f.values()) for f in train_features])\n",
    "    y_train = np.array(train_labels)\n",
    "    X_test = np.array([list(f.values()) for f in test_features])\n",
    "    y_test = np.array(test_labels)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "    clf.fit(X_train_normalized, y_train)\n",
    "\n",
    "    # Store the model for this subject\n",
    "    subject_models[subject] = clf\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = clf.predict(X_test_normalized)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy for {subject}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Aggregate metrics\n",
    "    metrics = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    precision_values, recall_values, f1_values, support_values = metrics\n",
    "\n",
    "    total_support_subject = sum(support_values)\n",
    "    weighted_precision = sum(p * s for p, s in zip(precision_values, support_values)) / total_support_subject\n",
    "    weighted_recall = sum(r * s for r, s in zip(recall_values, support_values)) / total_support_subject\n",
    "    weighted_f1 = sum(f * s for f, s in zip(f1_values, support_values)) / total_support_subject\n",
    "\n",
    "    total_weighted_precision += weighted_precision * total_support_subject\n",
    "    total_weighted_recall += weighted_recall * total_support_subject\n",
    "    total_weighted_f1 += weighted_f1 * total_support_subject\n",
    "    total_support += total_support_subject\n",
    "    total_accuracy += accuracy\n",
    "    total_subjects += 1\n",
    "\n",
    "    # Calculate additional metrics (Recall, F1, Precision)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Visualize Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=['movement', 'rest'], yticklabels=['movement', 'rest'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # Calculate and plot SHAP values\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "    shap_values = explainer.shap_values(X_test_normalized)\n",
    "\n",
    "    # Get the feature names (assuming all features are keys in one of the feature dictionaries)\n",
    "    feature_names = list(train_features[0].keys())\n",
    "\n",
    "    # Plot SHAP values for each class\n",
    "    for i, label in enumerate(clf.classes_):\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "        # Display SHAP summary plot\n",
    "        shap.summary_plot(shap_values[i], X_test, feature_names=feature_names, show=False)\n",
    "\n",
    "        # Create Explanation object for bar plot\n",
    "        expected_value = explainer.expected_value[i]\n",
    "        explanation = shap.Explanation(values=shap_values[i],\n",
    "                                      base_values=expected_value,\n",
    "                                      data=X_test,\n",
    "                                      feature_names=feature_names)\n",
    "\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "        # Display SHAP bar plot\n",
    "        shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Calculate final aggregated metrics\n",
    "final_precision = total_weighted_precision / total_support\n",
    "final_recall = total_weighted_recall / total_support\n",
    "final_f1 = total_weighted_f1 / total_support\n",
    "final_accuracy = total_accuracy / total_subjects\n",
    "\n",
    "final_metrics = {\n",
    "    \"Precision\": final_precision,\n",
    "    \"Recall\": final_recall,\n",
    "    \"F1-Score\": final_f1,\n",
    "    \"Support\": total_support,\n",
    "    \"Accuracy\": final_accuracy\n",
    "}\n",
    "\n",
    "print(\"Final Aggregated Metrics:\", final_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Local Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "import wfdb\n",
    "import shap\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define folder path\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/'  # Update with your path\n",
    "\n",
    "fs = 500  # Sampling frequency\n",
    "\n",
    "# Initialize aggregation variables\n",
    "total_weighted_precision = 0\n",
    "total_weighted_recall = 0\n",
    "total_weighted_f1 = 0\n",
    "total_support = 0\n",
    "total_accuracy = 0\n",
    "total_subjects = 0\n",
    "\n",
    "# Initialize data structures\n",
    "subject_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Initialize a dictionary to hold models for each subject\n",
    "subject_models = {}\n",
    "\n",
    "# List of keys to extract from both ECG and PPG features\n",
    "selected_keys_ecg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq', 'mean_nni','sdnn','sdsd','pnn20','pnn50','rmssd','sd1','sd2','respiratory_rate']\n",
    "selected_keys_ppg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq']\n",
    "\n",
    "# Load and organize data by subject and activity\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):\n",
    "        subject, activity = filename.split('_')[0], filename.split('_')[1].split('.')[0]\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "        subject_data[subject][activity] = record\n",
    "\n",
    "# Process data for each subject\n",
    "for subject in subject_data.keys():\n",
    "\n",
    "    print(f\"Processing subject: {subject}\")\n",
    "\n",
    "    train_features, test_features = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "\n",
    "    all_prefixed_features = []\n",
    "\n",
    "\n",
    "    for activity in subject_data[subject].keys():\n",
    "\n",
    "        print(f\"Processing activity: {activity}\")\n",
    "\n",
    "        record = subject_data[subject][activity]\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Extract local features\n",
    "        ecg_local_features = local_features(ecg_signal, fs, is_ecg=True)\n",
    "        pleth_2_local_features = local_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Split local windows 5/1\n",
    "        num_windows = len(ecg_local_features)\n",
    "        train_size = int(5/6 * num_windows)\n",
    "        ecg_train_local_features = ecg_local_features[:train_size]\n",
    "        pleth_2_train_local_features = pleth_2_local_features[:train_size]\n",
    "        ecg_test_local_features = ecg_local_features[train_size:]\n",
    "        pleth_2_test_local_features = pleth_2_local_features[train_size:]\n",
    "\n",
    "        # Prefix the selected keys for plotting later\n",
    "        prefixed_keys_ecg = [\"ECG_\" + key for key in selected_keys_ecg]\n",
    "        prefixed_keys_ppg = [\"PPG_\" + key for key in selected_keys_ppg]\n",
    "\n",
    "        # Combine and flatten features\n",
    "        train_combined_features = []\n",
    "        for ecg_feat, ppg_feat in zip(ecg_train_local_features, pleth_2_train_local_features):\n",
    "            combined = {**ecg_feat, **ppg_feat}\n",
    "            train_combined_features.append(list(combined.values()))\n",
    "\n",
    "        test_combined_features = []\n",
    "        for ecg_feat, ppg_feat in zip(ecg_test_local_features, pleth_2_test_local_features):\n",
    "            combined = {**ecg_feat, **ppg_feat}\n",
    "            test_combined_features.append(list(combined.values()))\n",
    "\n",
    "        # Aggregate the features across the sets\n",
    "        train_aggregated_features = np.mean(train_combined_features, axis=0)\n",
    "        test_aggregated_features = np.mean(test_combined_features, axis=0)\n",
    "\n",
    "        # Append the aggregated features as a single sample\n",
    "        train_features.append(train_aggregated_features)\n",
    "        test_features.append(test_aggregated_features)\n",
    "\n",
    "        # Append the label only once per activity\n",
    "        train_labels.append(activity)\n",
    "        test_labels.append(activity)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X_train = np.array(train_features)\n",
    "    y_train = np.array(train_labels)\n",
    "    X_test = np.array(test_features)\n",
    "    y_test = np.array(test_labels)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "    clf.fit(X_train_normalized, y_train)\n",
    "\n",
    "    # Store the model for this subject\n",
    "    subject_models[subject] = clf\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = clf.predict(X_test_normalized)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy for {subject}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Aggregate metrics\n",
    "    metrics = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    precision_values, recall_values, f1_values, support_values = metrics\n",
    "\n",
    "    total_support_subject = sum(support_values)\n",
    "    weighted_precision = sum(p * s for p, s in zip(precision_values, support_values)) / total_support_subject\n",
    "    weighted_recall = sum(r * s for r, s in zip(recall_values, support_values)) / total_support_subject\n",
    "    weighted_f1 = sum(f * s for f, s in zip(f1_values, support_values)) / total_support_subject\n",
    "\n",
    "    total_weighted_precision += weighted_precision * total_support_subject\n",
    "    total_weighted_recall += weighted_recall * total_support_subject\n",
    "    total_weighted_f1 += weighted_f1 * total_support_subject\n",
    "    total_support += total_support_subject\n",
    "    total_accuracy += accuracy\n",
    "    total_subjects += 1\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=['sit', 'walk', 'run'], yticklabels=['sit', 'walk', 'run'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # SHAP Value Calculation and Plotting\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "    shap_values = explainer.shap_values(X_test_normalized)\n",
    "\n",
    "    # For ECG features\n",
    "    for idx in range(len(ecg_train_local_features)):\n",
    "        suffix = \"_\" + str(idx + 1)\n",
    "        for key in prefixed_keys_ecg:\n",
    "            all_prefixed_features.append(key + suffix)\n",
    "\n",
    "    # For PPG features\n",
    "    for idx in range(len(pleth_2_train_local_features)):\n",
    "        suffix = \"_\" + str(idx + 1)\n",
    "        for key in prefixed_keys_ppg:\n",
    "            all_prefixed_features.append(key + suffix)\n",
    "\n",
    "    # Plot SHAP values for each class\n",
    "    for i, label in enumerate(clf.classes_):\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "        # Display SHAP summary plot\n",
    "        shap.summary_plot(shap_values[i], X_test, feature_names=all_prefixed_features, show=False)\n",
    "\n",
    "        # Create Explanation object for bar plot\n",
    "        expected_value = explainer.expected_value[i]\n",
    "        explanation = shap.Explanation(values=shap_values[i],\n",
    "                                      base_values=expected_value,\n",
    "                                      data=X_test,\n",
    "                                      feature_names=all_prefixed_features)\n",
    "\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "        # Display SHAP bar plot\n",
    "        shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Calculate final aggregated metrics\n",
    "final_precision = total_weighted_precision / total_support\n",
    "final_recall = total_weighted_recall / total_support\n",
    "final_f1 = total_weighted_f1 / total_support\n",
    "final_accuracy = total_accuracy / total_subjects\n",
    "\n",
    "final_metrics = {\n",
    "    \"Precision\": final_precision,\n",
    "    \"Recall\": final_recall,\n",
    "    \"F1-Score\": final_f1,\n",
    "    \"Support\": total_support,\n",
    "    \"Accuracy\": final_accuracy\n",
    "}\n",
    "\n",
    "print(\"Final Aggregated Metrics:\", final_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import os\n",
    "import wfdb\n",
    "import shap\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Define folder path\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/'  # Update with your path\n",
    "\n",
    "fs = 500  # Sampling frequency\n",
    "\n",
    "# Initialize aggregation variables\n",
    "total_weighted_precision = 0\n",
    "total_weighted_recall = 0\n",
    "total_weighted_f1 = 0\n",
    "total_support = 0\n",
    "total_accuracy = 0\n",
    "total_subjects = 0\n",
    "\n",
    "# Initialize data structures\n",
    "subject_data = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "# Initialize a dictionary to hold models for each subject\n",
    "subject_models = {}\n",
    "\n",
    "# List of keys to extract from both ECG and PPG features\n",
    "selected_keys_ecg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq', 'mean_nni','sdnn','sdsd','pnn20','pnn50','rmssd','sd1','sd2','respiratory_rate']\n",
    "selected_keys_ppg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq']\n",
    "\n",
    "# Load and organize data by subject and activity\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):\n",
    "        subject, activity = filename.split('_')[0], filename.split('_')[1].split('.')[0]\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "        subject_data[subject][activity] = record\n",
    "\n",
    "# Process data for each subject\n",
    "for subject in subject_data.keys():\n",
    "\n",
    "    print(f\"Processing subject: {subject}\")\n",
    "\n",
    "    train_features, test_features = [], []\n",
    "    train_labels, test_labels = [], []\n",
    "\n",
    "    all_prefixed_features = []\n",
    "\n",
    "    for activity in subject_data[subject].keys():\n",
    "\n",
    "        print(f\"Processing activity: {activity}\")\n",
    "\n",
    "        # Convert to binary classes ('movement' and 'rest')\n",
    "        binary_activity = 'movement' if activity in ['run', 'walk'] else 'rest'\n",
    "\n",
    "        record = subject_data[subject][activity]\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Extract local features\n",
    "        ecg_local_features = local_features(ecg_signal, fs, is_ecg=True)\n",
    "        pleth_2_local_features = local_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Split local windows 5/1\n",
    "        num_windows = len(ecg_local_features)\n",
    "        train_size = int(5/6 * num_windows)\n",
    "        ecg_train_local_features = ecg_local_features[:train_size]\n",
    "        pleth_2_train_local_features = pleth_2_local_features[:train_size]\n",
    "        ecg_test_local_features = ecg_local_features[train_size:]\n",
    "        pleth_2_test_local_features = pleth_2_local_features[train_size:]\n",
    "\n",
    "        # Prefix the selected keys for plotting later\n",
    "        prefixed_keys_ecg = [\"ECG_\" + key for key in selected_keys_ecg]\n",
    "        prefixed_keys_ppg = [\"PPG_\" + key for key in selected_keys_ppg]\n",
    "\n",
    "        # Combine and flatten features\n",
    "        train_combined_features = []\n",
    "        for ecg_feat, ppg_feat in zip(ecg_train_local_features, pleth_2_train_local_features):\n",
    "            combined = {**ecg_feat, **ppg_feat}\n",
    "            train_combined_features.append(list(combined.values()))\n",
    "\n",
    "        test_combined_features = []\n",
    "        for ecg_feat, ppg_feat in zip(ecg_test_local_features, pleth_2_test_local_features):\n",
    "            combined = {**ecg_feat, **ppg_feat}\n",
    "            test_combined_features.append(list(combined.values()))\n",
    "\n",
    "        # Aggregate the features across the sets\n",
    "        train_aggregated_features = np.mean(train_combined_features, axis=0)\n",
    "        test_aggregated_features = np.mean(test_combined_features, axis=0)\n",
    "\n",
    "        # Append the aggregated features as a single sample\n",
    "        train_features.append(train_aggregated_features)\n",
    "        test_features.append(test_aggregated_features)\n",
    "\n",
    "        # Append the label only once per activity\n",
    "        train_labels.append(binary_activity)\n",
    "        test_labels.append(binary_activity)\n",
    "\n",
    "    # Convert to NumPy arrays\n",
    "    X_train = np.array(train_features)\n",
    "    y_train = np.array(train_labels)\n",
    "    X_test = np.array(test_features)\n",
    "    y_test = np.array(test_labels)\n",
    "\n",
    "    # Normalize the data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "    # Train the classifier\n",
    "    clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "    clf.fit(X_train_normalized, y_train)\n",
    "\n",
    "    # Store the model for this subject\n",
    "    subject_models[subject] = clf\n",
    "\n",
    "    # Predict on the test set\n",
    "    y_pred = clf.predict(X_test_normalized)\n",
    "\n",
    "    # Calculate and print the accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Test Accuracy for {subject}: {accuracy * 100:.2f}%\")\n",
    "\n",
    "    # Aggregate metrics\n",
    "    metrics = precision_recall_fscore_support(y_test, y_pred, average=None)\n",
    "    precision_values, recall_values, f1_values, support_values = metrics\n",
    "\n",
    "    total_support_subject = sum(support_values)\n",
    "    weighted_precision = sum(p * s for p, s in zip(precision_values, support_values)) / total_support_subject\n",
    "    weighted_recall = sum(r * s for r, s in zip(recall_values, support_values)) / total_support_subject\n",
    "    weighted_f1 = sum(f * s for f, s in zip(f1_values, support_values)) / total_support_subject\n",
    "\n",
    "    total_weighted_precision += weighted_precision * total_support_subject\n",
    "    total_weighted_recall += weighted_recall * total_support_subject\n",
    "    total_weighted_f1 += weighted_f1 * total_support_subject\n",
    "    total_support += total_support_subject\n",
    "    total_accuracy += accuracy\n",
    "    total_subjects += 1\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Confusion Matrix\n",
    "    conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=['movement', 'rest'], yticklabels=['movement', 'rest'])\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    # SHAP Value Calculation and Plotting\n",
    "    explainer = shap.TreeExplainer(clf)\n",
    "    shap_values = explainer.shap_values(X_test_normalized)\n",
    "\n",
    "    # For ECG features\n",
    "    for idx in range(len(ecg_train_local_features)):\n",
    "            suffix = \"_\" + str(idx + 1)\n",
    "            for key in selected_keys_ecg:\n",
    "                all_prefixed_features.append(key + suffix)\n",
    "\n",
    "    # For PPG features\n",
    "    for idx in range(len(pleth_2_train_local_features)):\n",
    "        suffix = \"_\" + str(idx + 1)\n",
    "        for key in selected_keys_ppg:\n",
    "            all_prefixed_features.append(key + suffix)\n",
    "\n",
    "    # Plot SHAP values for each class\n",
    "    for i, label in enumerate(clf.classes_):\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "        # Display SHAP summary plot\n",
    "        shap.summary_plot(shap_values[i], X_test, feature_names=all_prefixed_features, show=False)\n",
    "\n",
    "        # Create Explanation object for bar plot\n",
    "        expected_value = explainer.expected_value[i]\n",
    "        explanation = shap.Explanation(values=shap_values[i],\n",
    "                                      base_values=expected_value,\n",
    "                                      data=X_test,\n",
    "                                      feature_names=all_prefixed_features)\n",
    "\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "        # Display SHAP bar plot\n",
    "        shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Calculate final aggregated metrics\n",
    "final_precision = total_weighted_precision / total_support\n",
    "final_recall = total_weighted_recall / total_support\n",
    "final_f1 = total_weighted_f1 / total_support\n",
    "final_accuracy = total_accuracy / total_subjects\n",
    "\n",
    "final_metrics = {\n",
    "    \"Precision\": final_precision,\n",
    "    \"Recall\": final_recall,\n",
    "    \"F1-Score\": final_f1,\n",
    "    \"Support\": total_support,\n",
    "    \"Accuracy\": final_accuracy\n",
    "}\n",
    "\n",
    "print(\"Final Aggregated Metrics:\", final_metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
