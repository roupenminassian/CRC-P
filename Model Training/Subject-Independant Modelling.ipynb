{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Global Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import wfdb\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/' # Update with your path\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Sampling frequency\n",
    "fs = 500\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):  # Assuming the wfdb data format with .dat extension\n",
    "        # Extract the label from the filename (e.g., \"sit\" from \"s20_sit\")\n",
    "        label = filename.split('_')[1].split('.')[0]\n",
    "        labels.append(label)\n",
    "\n",
    "        # Construct the record name without extensions\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "\n",
    "        # Load the record using wfdb\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Extract global features\n",
    "        ecg_features_raw = global_features(ecg_signal, fs, is_ecg=True)\n",
    "        ppg_features_raw = global_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Prefix the feature names to differentiate\n",
    "        ecg_features = {\"ECG_\" + k: v for k, v in ecg_features_raw.items()}\n",
    "        ppg_features = {\"PPG_\" + k: v for k, v in ppg_features_raw.items()}\n",
    "\n",
    "        # Combine features\n",
    "        all_features = {**ecg_features, **ppg_features}\n",
    "        features.append(list(all_features.values()))\n",
    "\n",
    "# Convert features and labels into NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "all_accuracy = []\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5)  # 5-fold cross-validation\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(clf, X_normalized, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracies: {cross_val_accuracies}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(cross_val_accuracies):.2f}\")\n",
    "\n",
    "# Split the normalized dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = clf.classes_\n",
    "\n",
    "# Get the feature names (Assuming all_features.keys() has them)\n",
    "feature_names = list(all_features.keys())\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate additional metrics (Recall, F1, Precision)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=['sit', 'walk', 'run'], yticklabels=['sit', 'walk', 'run'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Calculate and plot shapley\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot SHAP values for each class\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "    # Display SHAP summary plot\n",
    "    shap.summary_plot(shap_values[i], X_test, feature_names=feature_names, show=False)\n",
    "\n",
    "    # Create Explanation object for bar plot\n",
    "    expected_value = explainer.expected_value[i]\n",
    "    explanation = shap.Explanation(values=shap_values[i],\n",
    "                                   base_values=expected_value,\n",
    "                                   data=X_test,\n",
    "                                   feature_names=feature_names)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "    # Display SHAP bar plot\n",
    "    shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in cv.split(X_normalized, y):\n",
    "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "    all_accuracy.append(accuracy)\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(all_accuracy)\n",
    "avg_precision = np.mean(all_precision)\n",
    "avg_recall = np.mean(all_recall)\n",
    "avg_f1 = np.mean(all_f1)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import wfdb\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/'  # Update with your path\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Sampling frequency\n",
    "fs = 500\n",
    "\n",
    "# Function to create directory structure\n",
    "def create_directory_structure(base_folder):\n",
    "    dir_structure = os.path.join(base_folder, \"Subject_Independent_Model\", \"Global\", \"Binary\")\n",
    "    if not os.path.exists(dir_structure):\n",
    "        os.makedirs(dir_structure)\n",
    "    return dir_structure\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):  # Assuming the wfdb data format with .dat extension\n",
    "        # Extract the label from the filename (e.g., \"sit\" from \"s20_sit\")\n",
    "        label = filename.split('_')[1].split('.')[0]\n",
    "\n",
    "        # Convert 'run' and 'walk' labels to 'movement'\n",
    "        if label in ['run', 'walk']:\n",
    "            label = 'movement'\n",
    "\n",
    "        if label == 'sit':\n",
    "            label = 'rest'\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "        # Construct the record name without extensions\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "\n",
    "        # Load the record using wfdb\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Extract global features\n",
    "        ecg_features_raw = global_features(ecg_signal, fs, is_ecg=True)\n",
    "        ppg_features_raw = global_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Prefix the feature names to differentiate\n",
    "        ecg_features = {\"ECG_\" + k: v for k, v in ecg_features_raw.items()}\n",
    "        ppg_features = {\"PPG_\" + k: v for k, v in ppg_features_raw.items()}\n",
    "\n",
    "        # Combine features\n",
    "        all_features = {**ecg_features, **ppg_features}\n",
    "        features.append(list(all_features.values()))\n",
    "\n",
    "# Convert features and labels into NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "all_accuracy = []\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5)  # 5-fold cross-validation\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(clf, X_normalized, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracies: {cross_val_accuracies}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(cross_val_accuracies):.2f}\")\n",
    "\n",
    "# Split the normalized dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = clf.classes_\n",
    "\n",
    "# Get the feature names (Assuming all_features.keys() has them)\n",
    "feature_names = list(all_features.keys())\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate additional metrics (Recall, F1, Precision)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Calculate and plot Shapley values\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot SHAP values for each class\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "    # Display SHAP summary plot\n",
    "    shap.summary_plot(shap_values[i], X_test, feature_names=feature_names, show=False)\n",
    "\n",
    "    # Create Explanation object for bar plot\n",
    "    expected_value = explainer.expected_value[i]\n",
    "    explanation = shap.Explanation(values=shap_values[i],\n",
    "                                   base_values=expected_value,\n",
    "                                   data=X_test,\n",
    "                                   feature_names=feature_names)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "    # Display SHAP bar plot\n",
    "    shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in cv.split(X_normalized, y):\n",
    "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "    all_accuracy.append(accuracy)\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(all_accuracy)\n",
    "avg_precision = np.mean(all_precision)\n",
    "avg_recall = np.mean(all_recall)\n",
    "avg_f1 = np.mean(all_f1)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Local Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import wfdb\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Folder containing your datasets\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/'  # Update with your path\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# List of keys to extract from both ECG and PPG features\n",
    "selected_keys_ecg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq', 'mean_nni','sdnn','sdsd','pnn20','pnn50','rmssd','sd1','sd2','respiratory_rate']\n",
    "selected_keys_ppg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq']\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):\n",
    "        # Extract the label from the filename\n",
    "        label = filename.split('_')[1].split('.')[0]\n",
    "        labels.append(label)\n",
    "\n",
    "        # Construct the record name without extensions\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "\n",
    "        # Load the record using wfdb\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Prefix the selected keys\n",
    "        prefixed_keys_ecg = [\"ECG_\" + key for key in selected_keys_ecg]\n",
    "        prefixed_keys_ppg = [\"PPG_\" + key for key in selected_keys_ppg]\n",
    "\n",
    "        # Extract local features\n",
    "        ecg_local_features = local_features(ecg_signal, fs, is_ecg=True)\n",
    "        ppg_local_features = local_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Combine and flatten features using the selected keys\n",
    "        flattened_features = []\n",
    "        for idx, (ecg_feat, ppg_feat) in enumerate(zip(ecg_local_features, ppg_local_features)):\n",
    "            selected_ecg_values = [ecg_feat[key] for key in selected_keys_ecg]\n",
    "            selected_ppg_values = [ppg_feat[key] for key in selected_keys_ppg]\n",
    "            flattened_features.extend(selected_ecg_values + selected_ppg_values)\n",
    "\n",
    "        features.append(flattened_features)\n",
    "\n",
    "# Convert features and labels into NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "all_accuracy = []\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5)  # 5-fold cross-validation\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracies: {cross_val_accuracies}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(cross_val_accuracies):.2f}\")\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = clf.classes_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate additional metrics (Recall, F1, Precision)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Calculate and plot Shapley values\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Combine the prefixed feature names for SHAP plotting\n",
    "all_prefixed_features = []\n",
    "\n",
    "# For ECG features\n",
    "for idx in range(len(ecg_local_features)):\n",
    "    suffix = \"_\" + str(idx + 1)\n",
    "    for key in prefixed_keys_ecg:\n",
    "        all_prefixed_features.append(key + suffix)\n",
    "\n",
    "# For PPG features\n",
    "for idx in range(len(ppg_local_features)):\n",
    "    suffix = \"_\" + str(idx + 1)\n",
    "    for key in prefixed_keys_ppg:\n",
    "        all_prefixed_features.append(key + suffix)\n",
    "\n",
    "# Plot the summary plot to show the most important features\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "    # Display SHAP summary plot\n",
    "    shap.summary_plot(shap_values[i], X_test, feature_names=all_prefixed_features, show=False)\n",
    "\n",
    "    # Create Explanation object for bar plot\n",
    "    expected_value = explainer.expected_value[i]\n",
    "    explanation = shap.Explanation(values=shap_values[i],\n",
    "                                   base_values=expected_value,\n",
    "                                   data=X_test,\n",
    "                                   feature_names=all_prefixed_features)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "    # Display SHAP bar plot\n",
    "    shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in cv.split(X_normalized, y):\n",
    "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "    all_accuracy.append(accuracy)\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(all_accuracy)\n",
    "avg_precision = np.mean(all_precision)\n",
    "avg_recall = np.mean(all_recall)\n",
    "avg_f1 = np.mean(all_f1)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# Folder containing your datasets\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/' # Update with your path\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# List of keys to extract from both ECG and PPG features\n",
    "selected_keys_ecg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq', 'mean_nni','sdnn','sdsd','pnn20','pnn50','rmssd','sd1','sd2','respiratory_rate']\n",
    "selected_keys_ppg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq']\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):\n",
    "        # Extract the label from the filename\n",
    "        label = filename.split('_')[1].split('.')[0]\n",
    "\n",
    "        # Convert 'run' and 'walk' labels to 'movement'\n",
    "        if label in ['run', 'walk']:\n",
    "            label = 'movement'\n",
    "\n",
    "        if label == 'sit':\n",
    "            label = 'rest'\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "        # Construct the record name without extensions\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "\n",
    "        # Load the record using wfdb\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Prefix the selected keys for plotting later\n",
    "        prefixed_keys_ecg = [\"ECG_\" + key for key in selected_keys_ecg]\n",
    "        prefixed_keys_ppg = [\"PPG_\" + key for key in selected_keys_ppg]\n",
    "\n",
    "        # Extract local features\n",
    "        ecg_local_features = local_features(ecg_signal, fs, is_ecg=True)\n",
    "        ppg_local_features = local_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Combine and flatten features using the selected keys\n",
    "        flattened_features = []\n",
    "        for idx, (ecg_feat, ppg_feat) in enumerate(zip(ecg_local_features, ppg_local_features)):\n",
    "            selected_ecg_values = [ecg_feat[key] for key in selected_keys_ecg]\n",
    "            selected_ppg_values = [ppg_feat[key] for key in selected_keys_ppg]\n",
    "            flattened_features.extend(selected_ecg_values + selected_ppg_values)\n",
    "\n",
    "        features.append(flattened_features)\n",
    "\n",
    "# Convert features and labels into NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "all_accuracy = []\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5)  # 5-fold cross-validation\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracies: {cross_val_accuracies}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(cross_val_accuracies):.2f}\")\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = clf.classes_\n",
    "\n",
    "# Get the feature names (Assuming all_features.keys() has them)\n",
    "feature_names = list(all_features.keys())\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate additional metrics (Recall, F1, Precision)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Calculate and plot Shapley values\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Combine the prefixed feature names for SHAP plotting\n",
    "all_prefixed_features = []\n",
    "\n",
    "# For ECG features\n",
    "for idx in range(len(ecg_local_features)):\n",
    "    suffix = \"_\" + str(idx + 1)\n",
    "    for key in prefixed_keys_ecg:\n",
    "        all_prefixed_features.append(key + suffix)\n",
    "\n",
    "# For PPG features\n",
    "for idx in range(len(ppg_local_features)):\n",
    "    suffix = \"_\" + str(idx + 1)\n",
    "    for key in prefixed_keys_ppg:\n",
    "        all_prefixed_features.append(key + suffix)\n",
    "\n",
    "# Plot the summary plot to show the most important features\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "    # Display SHAP summary plot\n",
    "    shap.summary_plot(shap_values[i], X_test, feature_names=all_prefixed_features, show=False)\n",
    "\n",
    "    # Create Explanation object for bar plot\n",
    "    expected_value = explainer.expected_value[i]\n",
    "    explanation = shap.Explanation(values=shap_values[i],\n",
    "                                   base_values=expected_value,\n",
    "                                   data=X_test,\n",
    "                                   feature_names=all_prefixed_features)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "    # Display SHAP bar plot\n",
    "    shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in cv.split(X_normalized, y):\n",
    "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "    all_accuracy.append(accuracy)\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(all_accuracy)\n",
    "avg_precision = np.mean(all_precision)\n",
    "avg_recall = np.mean(all_recall)\n",
    "avg_f1 = np.mean(all_f1)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
