{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install heartpy wfdb shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.signal\n",
    "from scipy.fftpack import fft, fftfreq\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import skew, kurtosis\n",
    "import pywt\n",
    "import heartpy as hp\n",
    "from scipy.signal import butter, lfilter\n",
    "import pywt\n",
    "\n",
    "def bandpass_filter(data, lowcut, highcut, fs, order=2):\n",
    "    nyquist = 0.5 * fs\n",
    "    low = lowcut / nyquist\n",
    "    high = highcut / nyquist\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "def preprocess_signal(signal, fs):\n",
    "    # Bandpass filtering\n",
    "    signal = bandpass_filter(signal, 0.5, 5.0, fs)  # Adjust these values as needed\n",
    "\n",
    "    return signal\n",
    "\n",
    "def global_features(signal, fs, is_ecg=False):\n",
    "\n",
    "    signal = preprocess_signal(signal, fs)\n",
    "    return common_features(signal, fs, is_ecg)\n",
    "\n",
    "def local_features(signal, fs, is_ecg=False):\n",
    "    features_list = []\n",
    "\n",
    "    # Constants defining the number of windows and the number of features\n",
    "    NUM_WINDOWS = 6\n",
    "    NUM_FEATURES_PER_WINDOW = 10\n",
    "    window_size = len(signal) // NUM_WINDOWS\n",
    "\n",
    "    cutoff_freq = 10.0  # You can adjust this based on your knowledge of the signal\n",
    "    signal = preprocess_signal(signal, fs)\n",
    "\n",
    "    for i in range(NUM_WINDOWS):\n",
    "        start_idx = i * window_size\n",
    "        end_idx = (i + 1) * window_size\n",
    "        neighborhood = signal[start_idx:end_idx]\n",
    "\n",
    "        features = common_features(neighborhood, fs, is_ecg)\n",
    "        selected_features = [features[key] for key in sorted(features.keys())]#[:NUM_FEATURES_PER_WINDOW]]\n",
    "        features_list.append(features)\n",
    "\n",
    "    return features_list\n",
    "\n",
    "def common_features(signal, fs, is_ecg=False):\n",
    "    features = {}\n",
    "\n",
    "    # Ensure signal is a 1D array\n",
    "    signal = np.squeeze(signal)\n",
    "\n",
    "    # Check for NaN values and handle them if necessary\n",
    "    if np.isnan(signal).any():\n",
    "        signal = signal[~np.isnan(signal)]\n",
    "\n",
    "    # Verify if the signal has at least one element to avoid errors\n",
    "    if signal.size == 0:\n",
    "        # Handle the empty signal case by returning empty features\n",
    "        return features\n",
    "\n",
    "    features['mean'] = np.mean(signal)\n",
    "    features['median'] = np.median(signal)\n",
    "    features['variance'] = np.var(signal)\n",
    "    features['std_dev'] = np.std(signal)\n",
    "    features['skewness'] = skew(signal)\n",
    "    features['kurtosis'] = kurtosis(signal)\n",
    "\n",
    "    peaks, _ = scipy.signal.find_peaks(signal)\n",
    "    valleys, _ = scipy.signal.find_peaks(-signal)\n",
    "    features['num_peaks'] = len(peaks)\n",
    "    features['num_valleys'] = len(valleys)\n",
    "\n",
    "    fft_vals = fft(signal)\n",
    "    fft_freq = fftfreq(len(signal), 1/fs)\n",
    "    norm_vals = np.abs(fft_vals)\n",
    "    norm_vals = norm_vals / sum(norm_vals)\n",
    "    features['spectral_entropy'] = -sum(norm_vals * np.log2(norm_vals))\n",
    "\n",
    "    freqs, psd_values = welch(signal, fs=fs)\n",
    "    features['dom_freq'] = freqs[np.argmax(psd_values)]\n",
    "\n",
    "    cA, cD = pywt.dwt(signal, 'db1')\n",
    "\n",
    "    if is_ecg:\n",
    "      # HeartPy analysis\n",
    "      wd, m = hp.process(hp.scale_data(signal), fs)  # Error line\n",
    "\n",
    "      features['mean_nni'] = m['bpm']\n",
    "      features['sdnn'] = m['sdnn']\n",
    "      features['sdsd'] = m['sdsd']\n",
    "      features['pnn20'] = m['pnn20']\n",
    "      features['pnn50'] = m['pnn50']\n",
    "      features['rmssd'] = m['rmssd']\n",
    "      features['sd1'] = m['sd1']\n",
    "      features['sd2'] = m['sd2']\n",
    "      features['respiratory_rate'] = m['breathingrate']\n",
    "\n",
    "    return features\n",
    "\n",
    "def estimate_respiratory_rate(signal, fs):\n",
    "    freqs, psd_values = welch(signal, fs=fs)\n",
    "    respiratory_freq_range = (freqs >= 0.2) & (freqs <= 0.5)\n",
    "\n",
    "    if np.any(respiratory_freq_range):  # Check if there are any values within the specified range\n",
    "        dominant_respiratory_freq = freqs[respiratory_freq_range][np.argmax(psd_values[respiratory_freq_range])]\n",
    "        respiratory_rate = dominant_respiratory_freq * 60\n",
    "    else:\n",
    "        respiratory_rate = np.nan  # Return NaN if no values are found within the specified range\n",
    "\n",
    "    return respiratory_rate\n",
    "\n",
    "def detect_motion_artifact(signal, threshold=1.0):\n",
    "    first_derivative = np.abs(np.gradient(signal))\n",
    "    return np.mean(first_derivative) > threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Global Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import wfdb\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_recall_fscore_support\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/' # Update with your path\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Sampling frequency\n",
    "fs = 500\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):  # Assuming the wfdb data format with .dat extension\n",
    "        # Extract the label from the filename (e.g., \"sit\" from \"s20_sit\")\n",
    "        label = filename.split('_')[1].split('.')[0]\n",
    "        labels.append(label)\n",
    "\n",
    "        # Construct the record name without extensions\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "\n",
    "        # Load the record using wfdb\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Extract global features\n",
    "        ecg_features_raw = global_features(ecg_signal, fs, is_ecg=True)\n",
    "        ppg_features_raw = global_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Prefix the feature names to differentiate\n",
    "        ecg_features = {\"ECG_\" + k: v for k, v in ecg_features_raw.items()}\n",
    "        ppg_features = {\"PPG_\" + k: v for k, v in ppg_features_raw.items()}\n",
    "\n",
    "        # Combine features\n",
    "        all_features = {**ecg_features, **ppg_features}\n",
    "        features.append(list(all_features.values()))\n",
    "\n",
    "# Convert features and labels into NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "all_accuracy = []\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5)  # 5-fold cross-validation\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(clf, X_normalized, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracies: {cross_val_accuracies}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(cross_val_accuracies):.2f}\")\n",
    "\n",
    "# Split the normalized dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = clf.classes_\n",
    "\n",
    "# Get the feature names (Assuming all_features.keys() has them)\n",
    "feature_names = list(all_features.keys())\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate additional metrics (Recall, F1, Precision)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=['sit', 'walk', 'run'], yticklabels=['sit', 'walk', 'run'])\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Calculate and plot shapley\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot SHAP values for each class\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "    # Display SHAP summary plot\n",
    "    shap.summary_plot(shap_values[i], X_test, feature_names=feature_names, show=False)\n",
    "\n",
    "    # Create Explanation object for bar plot\n",
    "    expected_value = explainer.expected_value[i]\n",
    "    explanation = shap.Explanation(values=shap_values[i],\n",
    "                                   base_values=expected_value,\n",
    "                                   data=X_test,\n",
    "                                   feature_names=feature_names)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "    # Display SHAP bar plot\n",
    "    shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in cv.split(X_normalized, y):\n",
    "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "    all_accuracy.append(accuracy)\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(all_accuracy)\n",
    "avg_precision = np.mean(all_precision)\n",
    "avg_recall = np.mean(all_recall)\n",
    "avg_f1 = np.mean(all_f1)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "import wfdb\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/'  # Update with your path\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# Sampling frequency\n",
    "fs = 500\n",
    "\n",
    "# Function to create directory structure\n",
    "def create_directory_structure(base_folder):\n",
    "    dir_structure = os.path.join(base_folder, \"Subject_Independent_Model\", \"Global\", \"Binary\")\n",
    "    if not os.path.exists(dir_structure):\n",
    "        os.makedirs(dir_structure)\n",
    "    return dir_structure\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):  # Assuming the wfdb data format with .dat extension\n",
    "        # Extract the label from the filename (e.g., \"sit\" from \"s20_sit\")\n",
    "        label = filename.split('_')[1].split('.')[0]\n",
    "\n",
    "        # Convert 'run' and 'walk' labels to 'movement'\n",
    "        if label in ['run', 'walk']:\n",
    "            label = 'movement'\n",
    "\n",
    "        if label == 'sit':\n",
    "            label = 'rest'\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "        # Construct the record name without extensions\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "\n",
    "        # Load the record using wfdb\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Extract global features\n",
    "        ecg_features_raw = global_features(ecg_signal, fs, is_ecg=True)\n",
    "        ppg_features_raw = global_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Prefix the feature names to differentiate\n",
    "        ecg_features = {\"ECG_\" + k: v for k, v in ecg_features_raw.items()}\n",
    "        ppg_features = {\"PPG_\" + k: v for k, v in ppg_features_raw.items()}\n",
    "\n",
    "        # Combine features\n",
    "        all_features = {**ecg_features, **ppg_features}\n",
    "        features.append(list(all_features.values()))\n",
    "\n",
    "# Convert features and labels into NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Normalize the data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "all_accuracy = []\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5)  # 5-fold cross-validation\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(clf, X_normalized, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracies: {cross_val_accuracies}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(cross_val_accuracies):.2f}\")\n",
    "\n",
    "# Split the normalized dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = clf.classes_\n",
    "\n",
    "# Get the feature names (Assuming all_features.keys() has them)\n",
    "feature_names = list(all_features.keys())\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate additional metrics (Recall, F1, Precision)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Calculate and plot Shapley values\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Plot SHAP values for each class\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "    # Display SHAP summary plot\n",
    "    shap.summary_plot(shap_values[i], X_test, feature_names=feature_names, show=False)\n",
    "\n",
    "    # Create Explanation object for bar plot\n",
    "    expected_value = explainer.expected_value[i]\n",
    "    explanation = shap.Explanation(values=shap_values[i],\n",
    "                                   base_values=expected_value,\n",
    "                                   data=X_test,\n",
    "                                   feature_names=feature_names)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "    # Display SHAP bar plot\n",
    "    shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in cv.split(X_normalized, y):\n",
    "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "    all_accuracy.append(accuracy)\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(all_accuracy)\n",
    "avg_precision = np.mean(all_precision)\n",
    "avg_recall = np.mean(all_recall)\n",
    "avg_f1 = np.mean(all_f1)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Local Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shap\n",
    "import wfdb\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Folder containing your datasets\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/'  # Update with your path\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# List of keys to extract from both ECG and PPG features\n",
    "selected_keys_ecg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq', 'mean_nni','sdnn','sdsd','pnn20','pnn50','rmssd','sd1','sd2','respiratory_rate']\n",
    "selected_keys_ppg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq']\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):\n",
    "        # Extract the label from the filename\n",
    "        label = filename.split('_')[1].split('.')[0]\n",
    "        labels.append(label)\n",
    "\n",
    "        # Construct the record name without extensions\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "\n",
    "        # Load the record using wfdb\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Prefix the selected keys\n",
    "        prefixed_keys_ecg = [\"ECG_\" + key for key in selected_keys_ecg]\n",
    "        prefixed_keys_ppg = [\"PPG_\" + key for key in selected_keys_ppg]\n",
    "\n",
    "        # Extract local features\n",
    "        ecg_local_features = local_features(ecg_signal, fs, is_ecg=True)\n",
    "        ppg_local_features = local_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Combine and flatten features using the selected keys\n",
    "        flattened_features = []\n",
    "        for idx, (ecg_feat, ppg_feat) in enumerate(zip(ecg_local_features, ppg_local_features)):\n",
    "            selected_ecg_values = [ecg_feat[key] for key in selected_keys_ecg]\n",
    "            selected_ppg_values = [ppg_feat[key] for key in selected_keys_ppg]\n",
    "            flattened_features.extend(selected_ecg_values + selected_ppg_values)\n",
    "\n",
    "        features.append(flattened_features)\n",
    "\n",
    "# Convert features and labels into NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "all_accuracy = []\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5)  # 5-fold cross-validation\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracies: {cross_val_accuracies}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(cross_val_accuracies):.2f}\")\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = clf.classes_\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate additional metrics (Recall, F1, Precision)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Calculate and plot Shapley values\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Combine the prefixed feature names for SHAP plotting\n",
    "all_prefixed_features = []\n",
    "\n",
    "# For ECG features\n",
    "for idx in range(len(ecg_local_features)):\n",
    "    suffix = \"_\" + str(idx + 1)\n",
    "    for key in prefixed_keys_ecg:\n",
    "        all_prefixed_features.append(key + suffix)\n",
    "\n",
    "# For PPG features\n",
    "for idx in range(len(ppg_local_features)):\n",
    "    suffix = \"_\" + str(idx + 1)\n",
    "    for key in prefixed_keys_ppg:\n",
    "        all_prefixed_features.append(key + suffix)\n",
    "\n",
    "# Plot the summary plot to show the most important features\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "    # Display SHAP summary plot\n",
    "    shap.summary_plot(shap_values[i], X_test, feature_names=all_prefixed_features, show=False)\n",
    "\n",
    "    # Create Explanation object for bar plot\n",
    "    expected_value = explainer.expected_value[i]\n",
    "    explanation = shap.Explanation(values=shap_values[i],\n",
    "                                   base_values=expected_value,\n",
    "                                   data=X_test,\n",
    "                                   feature_names=all_prefixed_features)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "    # Display SHAP bar plot\n",
    "    shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in cv.split(X_normalized, y):\n",
    "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "    all_accuracy.append(accuracy)\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(all_accuracy)\n",
    "avg_precision = np.mean(all_precision)\n",
    "avg_recall = np.mean(all_recall)\n",
    "avg_f1 = np.mean(all_f1)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wfdb\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "# Folder containing your datasets\n",
    "folder_path = '/Users/roupenminassian/physionet.org/files/pulse-transit-time-ppg/1.1.0/Data/' # Update with your path\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "# List of keys to extract from both ECG and PPG features\n",
    "selected_keys_ecg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq', 'mean_nni','sdnn','sdsd','pnn20','pnn50','rmssd','sd1','sd2','respiratory_rate']\n",
    "selected_keys_ppg = ['mean', 'median', 'variance', 'std_dev', 'skewness', 'kurtosis', 'num_peaks', 'num_valleys', 'spectral_entropy', 'dom_freq']\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".dat\"):\n",
    "        # Extract the label from the filename\n",
    "        label = filename.split('_')[1].split('.')[0]\n",
    "\n",
    "        # Convert 'run' and 'walk' labels to 'movement'\n",
    "        if label in ['run', 'walk']:\n",
    "            label = 'movement'\n",
    "\n",
    "        if label == 'sit':\n",
    "            label = 'rest'\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "        # Construct the record name without extensions\n",
    "        record_name = os.path.join(folder_path, filename.split('.')[0])\n",
    "\n",
    "        # Load the record using wfdb\n",
    "        record = wfdb.rdrecord(record_name)\n",
    "\n",
    "        # Extract ECG and PPG signals\n",
    "        ecg_index = record.sig_name.index('ecg')\n",
    "        ecg_signal = record.p_signal[:, ecg_index]\n",
    "        pleth_2_index = record.sig_name.index('pleth_2')\n",
    "        pleth_2_signal = record.p_signal[:, pleth_2_index]\n",
    "\n",
    "        # Prefix the selected keys for plotting later\n",
    "        prefixed_keys_ecg = [\"ECG_\" + key for key in selected_keys_ecg]\n",
    "        prefixed_keys_ppg = [\"PPG_\" + key for key in selected_keys_ppg]\n",
    "\n",
    "        # Extract local features\n",
    "        ecg_local_features = local_features(ecg_signal, fs, is_ecg=True)\n",
    "        ppg_local_features = local_features(pleth_2_signal, fs, is_ecg=False)\n",
    "\n",
    "        # Combine and flatten features using the selected keys\n",
    "        flattened_features = []\n",
    "        for idx, (ecg_feat, ppg_feat) in enumerate(zip(ecg_local_features, ppg_local_features)):\n",
    "            selected_ecg_values = [ecg_feat[key] for key in selected_keys_ecg]\n",
    "            selected_ppg_values = [ppg_feat[key] for key in selected_keys_ppg]\n",
    "            flattened_features.extend(selected_ecg_values + selected_ppg_values)\n",
    "\n",
    "        features.append(flattened_features)\n",
    "\n",
    "# Convert features and labels into NumPy arrays\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "all_precision = []\n",
    "all_recall = []\n",
    "all_f1 = []\n",
    "all_accuracy = []\n",
    "\n",
    "# Cross-validation setup\n",
    "cv = StratifiedKFold(n_splits=5)  # 5-fold cross-validation\n",
    "clf = RandomForestClassifier(n_estimators=1000, random_state=42)\n",
    "cross_val_accuracies = cross_val_score(clf, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Cross-Validation Accuracies: {cross_val_accuracies}\")\n",
    "print(f\"Average Cross-Validation Accuracy: {np.mean(cross_val_accuracies):.2f}\")\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Get the class labels\n",
    "class_labels = clf.classes_\n",
    "\n",
    "# Get the feature names (Assuming all_features.keys() has them)\n",
    "feature_names = list(all_features.keys())\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate additional metrics (Recall, F1, Precision)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Visualize Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=np.unique(y))\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap=\"YlGnBu\", xticklabels=np.unique(y), yticklabels=np.unique(y))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Calculate and plot Shapley values\n",
    "explainer = shap.TreeExplainer(clf)\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# Combine the prefixed feature names for SHAP plotting\n",
    "all_prefixed_features = []\n",
    "\n",
    "# For ECG features\n",
    "for idx in range(len(ecg_local_features)):\n",
    "    suffix = \"_\" + str(idx + 1)\n",
    "    for key in prefixed_keys_ecg:\n",
    "        all_prefixed_features.append(key + suffix)\n",
    "\n",
    "# For PPG features\n",
    "for idx in range(len(ppg_local_features)):\n",
    "    suffix = \"_\" + str(idx + 1)\n",
    "    for key in prefixed_keys_ppg:\n",
    "        all_prefixed_features.append(key + suffix)\n",
    "\n",
    "# Plot the summary plot to show the most important features\n",
    "for i, label in enumerate(class_labels):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Summary for class {label}\")\n",
    "\n",
    "    # Display SHAP summary plot\n",
    "    shap.summary_plot(shap_values[i], X_test, feature_names=all_prefixed_features, show=False)\n",
    "\n",
    "    # Create Explanation object for bar plot\n",
    "    expected_value = explainer.expected_value[i]\n",
    "    explanation = shap.Explanation(values=shap_values[i],\n",
    "                                   base_values=expected_value,\n",
    "                                   data=X_test,\n",
    "                                   feature_names=all_prefixed_features)\n",
    "\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    plt.title(f\"SHAP Bar for class {label}\")\n",
    "\n",
    "    # Display SHAP bar plot\n",
    "    shap.plots.bar(explanation, max_display=20, show=False)\n",
    "\n",
    "# Loop through each fold\n",
    "for train_index, test_index in cv.split(X_normalized, y):\n",
    "    X_train, X_test = X_normalized[train_index], X_normalized[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "\n",
    "    all_accuracy.append(accuracy)\n",
    "    all_precision.append(precision)\n",
    "    all_recall.append(recall)\n",
    "    all_f1.append(f1)\n",
    "\n",
    "# Calculate average metrics\n",
    "avg_accuracy = np.mean(all_accuracy)\n",
    "avg_precision = np.mean(all_precision)\n",
    "avg_recall = np.mean(all_recall)\n",
    "avg_f1 = np.mean(all_f1)\n",
    "\n",
    "print(f\"Average Accuracy: {avg_accuracy * 100:.2f}%\")\n",
    "print(f\"Average Precision: {avg_precision:.2f}\")\n",
    "print(f\"Average Recall: {avg_recall:.2f}\")\n",
    "print(f\"Average F1-score: {avg_f1:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
